import React, { useState, useEffect } from 'react';
import { Pressable, StyleSheet, Alert, Platform } from 'react-native';
import CustomText from './CustomText';

interface AdvancedSTTButtonProps {
  onResult: (text: string) => void;
  disabled?: boolean;
  style?: any;
}

export default function AdvancedSTTButton({ onResult, disabled = false, style }: AdvancedSTTButtonProps) {
  const [isListening, setIsListening] = useState(false);
  const [isSupported, setIsSupported] = useState(false);

  useEffect(() => {
    // ì›¹ í™˜ê²½ì—ì„œ Speech Recognition API ì§€ì› í™•ì¸
    if (Platform.OS === 'web') {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      setIsSupported(!!SpeechRecognition);
    } else {
      // ëª¨ë°”ì¼ í™˜ê²½ì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  ê°€ì •
      setIsSupported(false);
    }
  }, []);

  const startListening = () => {
    if (Platform.OS === 'web' && isSupported) {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      
      recognition.continuous = false;
      recognition.interimResults = true; // ì¤‘ê°„ ê²°ê³¼ë„ ë°›ê¸°
      recognition.lang = 'ko-KR'; // í•œêµ­ì–´ ì„¤ì •
      recognition.maxAlternatives = 1;
      
      let finalTranscript = '';
      
      recognition.onstart = () => {
        setIsListening(true);
      };
      
      recognition.onresult = (event: any) => {
        let interimTranscript = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }
        
        // ì¤‘ê°„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œ
        if (interimTranscript) {
          onResult(finalTranscript + interimTranscript);
        }
        
        // ìµœì¢… ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì²˜ë¦¬
        if (finalTranscript) {
          onResult(finalTranscript);
          setIsListening(false);
        }
      };
      
      recognition.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        setIsListening(false);
        
        let errorMessage = 'ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
        switch (event.error) {
          case 'no-speech':
            errorMessage = 'ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.';
            break;
          case 'audio-capture':
            errorMessage = 'ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
            break;
          case 'not-allowed':
            errorMessage = 'ë§ˆì´í¬ ê¶Œí•œì´ í—ˆìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
            break;
          case 'network':
            errorMessage = 'ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
            break;
          default:
            errorMessage = `ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${event.error}`;
        }
        
        Alert.alert('ìŒì„± ì¸ì‹ ì˜¤ë¥˜', errorMessage);
      };
      
      recognition.onend = () => {
        setIsListening(false);
      };
      
      try {
        recognition.start();
      } catch (error) {
        console.error('Recognition start error:', error);
        setIsListening(false);
        Alert.alert('ìŒì„± ì¸ì‹ ì˜¤ë¥˜', 'ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }
    } else {
      Alert.alert(
        'ìŒì„± ì¸ì‹ ì§€ì› ì•ˆí•¨', 
        'í˜„ì¬ í™˜ê²½ì—ì„œëŠ” ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.'
      );
    }
  };

  const stopListening = () => {
    if (Platform.OS === 'web') {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      if (SpeechRecognition) {
        // ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ì¤‘ì§€ë¨
        setIsListening(false);
      }
    }
  };

  if (!isSupported && Platform.OS !== 'web') {
    return null; // ëª¨ë°”ì¼ì—ì„œëŠ” STT ë²„íŠ¼ì„ í‘œì‹œí•˜ì§€ ì•ŠìŒ
  }

  return (
    <Pressable
      style={[
        styles.button,
        isListening && styles.listeningButton,
        disabled && styles.disabledButton,
        style
      ]}
      onPress={isListening ? stopListening : startListening}
      disabled={disabled || !isSupported}
      android_ripple={{ color: '#e5e7eb' }}
    >
      <CustomText style={[
        styles.buttonText,
        isListening && styles.listeningText,
        disabled && styles.disabledText
      ]}>
        {isListening ? 'ğŸ¤ ë“£ëŠ” ì¤‘...' : 'ğŸ¤ ìŒì„± ì…ë ¥'}
      </CustomText>
    </Pressable>
  );
}

const styles = StyleSheet.create({
  button: {
    backgroundColor: '#f8f9fa',
    borderWidth: 1,
    borderColor: '#dee2e6',
    borderRadius: 8,
    paddingHorizontal: 16,
    paddingVertical: 8,
    alignItems: 'center',
    justifyContent: 'center',
    minWidth: 100,
  },
  listeningButton: {
    backgroundColor: '#e3f2fd',
    borderColor: '#2196f3',
    borderWidth: 2,
  },
  disabledButton: {
    backgroundColor: '#f5f5f5',
    borderColor: '#e0e0e0',
    opacity: 0.6,
  },
  buttonText: {
    fontSize: 14,
    color: '#495057',
    fontWeight: '600',
  },
  listeningText: {
    color: '#1976d2',
    fontWeight: 'bold',
  },
  disabledText: {
    color: '#9e9e9e',
  },
});
